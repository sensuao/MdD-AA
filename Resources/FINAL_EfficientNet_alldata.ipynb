{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF9uvbXNVrVY"
      },
      "source": [
        "## Import packages"
      ],
      "id": "zF9uvbXNVrVY"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rtPGh2MAVrVa"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "id": "rtPGh2MAVrVa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jlchl4x2VrVg"
      },
      "source": [
        "Import Tensorflow and the Keras classes needed to construct our model."
      ],
      "id": "Jlchl4x2VrVg"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "E82grprdYPI0"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf"
      ],
      "id": "E82grprdYPI0"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L1WtoaOHVrVh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model, metrics\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "id": "L1WtoaOHVrVh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZZI6lNkVrVm"
      },
      "source": [
        "## Load data"
      ],
      "id": "UZZI6lNkVrVm"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCAjJLhr1fqC",
        "outputId": "9fe62cb1-9e13-4fcc-9ec5-51d91e85ee25"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "id": "HCAjJLhr1fqC"
    },
    {
      "cell_type": "code",
      "source": [
        "train_local_zip = '/content/drive/MyDrive/lulc-classification.zip'\n",
        "zip_ref = zipfile.ZipFile(train_local_zip, 'r')\n",
        "zip_ref.extractall('/content/sample_data/lulc-classification.zip')\n",
        "\n",
        "test_local_zip = '/content/drive/MyDrive/test.zip'\n",
        "zip_ref = zipfile.ZipFile(test_local_zip, 'r')\n",
        "zip_ref.extractall('/content/sample_data/lulc-tra-val/lulc-classificatio')\n",
        "\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "DmYx9zPa25Mz"
      },
      "execution_count": 5,
      "outputs": [],
      "id": "DmYx9zPa25Mz"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ly_AzZbb0diz"
      },
      "outputs": [],
      "source": [
        "PATH = '/content/sample_data/lulc-classification.zip/lulc-classification'"
      ],
      "id": "ly_AzZbb0diz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpmywIlsVrVx"
      },
      "source": [
        "After extracting its contents, assign variables with the proper file path for the training and validation set."
      ],
      "id": "VpmywIlsVrVx"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sRucI3QqVrVy"
      },
      "outputs": [],
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "test_dir = os.path.join(PATH, 'test')"
      ],
      "id": "sRucI3QqVrVy"
    },
    {
      "cell_type": "code",
      "source": [
        "train_BarrenLands_dir = os.path.join(train_dir, '1_BarrenLands___jpeg')"
      ],
      "metadata": {
        "id": "u8swHNapWkBc"
      },
      "id": "u8swHNapWkBc",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vc4u8e9hVrV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5305244c-9083-4add-b78a-663f6b3d570e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total training barren images: 354\n"
          ]
        }
      ],
      "source": [
        "num_barren_tr = len(os.listdir(train_BarrenLands_dir))\n",
        "\n",
        "print('total training barren images:', num_barren_tr)"
      ],
      "id": "vc4u8e9hVrV4"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3NqNselLVrWA"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 160\n",
        "img_width = 160"
      ],
      "id": "3NqNselLVrWA"
    },
    {
      "cell_type": "markdown",
      "id": "6HcE1TSqNRY2",
      "metadata": {
        "id": "6HcE1TSqNRY2"
      },
      "source": [
        "## Training and Validation Generators\n",
        "\n",
        "Now that you know the images you are dealing with, it is time for you to code the generators that will fed these images to your Network. For this, complete the `train_val_generators` function below:\n",
        "\n",
        "**Important Note:** The images have a resolution of 300x300 but the `flow_from_directory` method you will use allows you to set a target resolution. In this case, **set a `target_size` of (150, 150)**. This will heavily lower the number of trainable parameters in your final network, yielding much quicker training times without compromising the accuracy!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "AX5Q3NL_FXMT",
      "metadata": {
        "cellView": "code",
        "id": "AX5Q3NL_FXMT"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: train_val_generators\n",
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
        "  ### START CODE HERE\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class \n",
        "  # Don't forget to normalize pixel values and set arguments to augment the images \n",
        "  train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size=batch_size, \n",
        "                                                      class_mode='categorical',\n",
        "                                                      target_size=(img_width, img_height))\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  # Remember that validation data should not be augmented\n",
        "  validation_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      )\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                                batch_size=batch_size, \n",
        "                                                                class_mode='categorical',\n",
        "                                                                target_size=(img_width, img_height))\n",
        "  ### END CODE HERE\n",
        "  return train_generator, validation_generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8FLUUqMKFwVR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FLUUqMKFwVR",
        "outputId": "583e3e1c-7590-4160-e2d1-20e68619b09b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10266 images belonging to 29 classes.\n",
            "Found 0 images belonging to 0 classes.\n"
          ]
        }
      ],
      "source": [
        "# Test your generators\n",
        "train_generator, test_generator = train_val_generators(train_dir, test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TszKWhunQaj4",
      "metadata": {
        "id": "TszKWhunQaj4"
      },
      "source": [
        "**Expected Output:**\n",
        "```\n",
        "Found 1027 images belonging to 2 classes.\n",
        "Found 256 images belonging to 2 classes.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Izx51Ju1rXwd",
      "metadata": {
        "id": "Izx51Ju1rXwd"
      },
      "source": [
        "## Transfer learning - Create the pre-trained model\n",
        "\n",
        "Download the `inception V3` weights into the `/tmp/` directory:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "m = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_m/feature_vector/2\",\n",
        "                   trainable=False),  # Can be True, see below.\n",
        "      # Add a fully connected layer with 1024 hidden units and ReLU activation\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    # Add a dropout rate of 0. 2\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    layers.Dense(29, activation='softmax')\n",
        "])\n",
        "m.build([None, 480, 480, 3])  # Batch input shape."
      ],
      "metadata": {
        "id": "9yg2LwTKTATB"
      },
      "execution_count": 15,
      "outputs": [],
      "id": "9yg2LwTKTATB"
    },
    {
      "cell_type": "code",
      "source": [
        "m.compile(optimizer='Adam',\n",
        "          loss='categorical_crossentropy',\n",
        "          metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "Vey1RSWdJDPP"
      },
      "id": "Vey1RSWdJDPP",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "Blhq2MAUeyGA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Blhq2MAUeyGA",
        "outputId": "78718818-fac1-49c5-fb5c-b4838bd475b1",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "321/321 [==============================] - 145s 353ms/step - loss: 1.3717 - accuracy: 0.5697\n",
            "Epoch 2/5\n",
            "321/321 [==============================] - 108s 336ms/step - loss: 0.8936 - accuracy: 0.6998\n",
            "Epoch 3/5\n",
            "321/321 [==============================] - 107s 333ms/step - loss: 0.7810 - accuracy: 0.7387\n",
            "Epoch 4/5\n",
            "321/321 [==============================] - 107s 334ms/step - loss: 0.7146 - accuracy: 0.7504\n",
            "Epoch 5/5\n",
            "321/321 [==============================] - 108s 337ms/step - loss: 0.6691 - accuracy: 0.7650\n"
          ]
        }
      ],
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take a few epochs)\n",
        "initial_epochs = 5\n",
        "history = m.fit(train_generator,\n",
        "                    #batch_size = batch_size,\n",
        "                    #steps_per_epoch = num_barren_tr // batch_size,\n",
        "                    epochs = initial_epochs,\n",
        "                    #validation_steps = num_barren_val // batch_size,\n",
        "                    verbose = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Y94djl4t0sK5",
      "metadata": {
        "id": "Y94djl4t0sK5"
      },
      "source": [
        "The training should have stopped after less than 10 epochs and it should have reached an accuracy over 99,9% (firing the callback). This happened so quickly because of the pre-trained model you used, which already contained information to classify humans from horses. Really cool!\n",
        "\n",
        "Now take a quick look at the training and validation accuracies for each epoch of training:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g-4-4i9U1a0s",
      "metadata": {
        "id": "g-4-4i9U1a0s"
      },
      "source": [
        "You will need to submit this notebook for grading. To download it, click on the `File` tab in the upper left corner of the screen then click on `Download` -> `Download .ipynb`. You can name it anything you want as long as it is a valid `.ipynb` (jupyter notebook) file."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7w54-pbB1W9r",
      "metadata": {
        "id": "7w54-pbB1W9r"
      },
      "source": [
        "**Congratulations on finishing this week's assignment!**\n",
        "\n",
        "You have successfully implemented a convolutional neural network that leverages a pre-trained network to help you solve the problem of classifying humans from horses.\n",
        "\n",
        "**Keep it up!**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.trainable = True\n",
        "\n",
        "m.compile(optimizer=tf.keras.optimizers.Adam(1e-4),  # Low learning rate\n",
        "          loss = 'categorical_crossentropy', \n",
        "          metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "history_fine = m.fit(train_generator,\n",
        "                    #batch_size = batch_size,\n",
        "                    initial_epoch = history.epoch[-1],\n",
        "                    #steps_per_epoch = num_barren_tr // batch_size,\n",
        "                    #validation_steps = num_barren_val // batch_size,\n",
        "                    epochs = 20,\n",
        "                    verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDmvTeItESpL",
        "outputId": "c40bbc0b-b33d-45a9-b8e3-2960cf30b5b7"
      },
      "id": "IDmvTeItESpL",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/20\n",
            "321/321 [==============================] - 354s 982ms/step - loss: 2.1758 - accuracy: 0.5414\n",
            "Epoch 6/20\n",
            "321/321 [==============================] - 314s 977ms/step - loss: 0.8753 - accuracy: 0.7117\n",
            "Epoch 7/20\n",
            "321/321 [==============================] - 314s 977ms/step - loss: 0.6659 - accuracy: 0.7736\n",
            "Epoch 8/20\n",
            "321/321 [==============================] - 314s 977ms/step - loss: 0.5630 - accuracy: 0.8072\n",
            "Epoch 9/20\n",
            "321/321 [==============================] - 316s 983ms/step - loss: 0.5147 - accuracy: 0.8201\n",
            "Epoch 10/20\n",
            "321/321 [==============================] - 316s 984ms/step - loss: 0.4516 - accuracy: 0.8432\n",
            "Epoch 11/20\n",
            "321/321 [==============================] - 316s 983ms/step - loss: 0.4012 - accuracy: 0.8549\n",
            "Epoch 12/20\n",
            "321/321 [==============================] - 316s 984ms/step - loss: 0.3946 - accuracy: 0.8625\n",
            "Epoch 13/20\n",
            "321/321 [==============================] - 316s 984ms/step - loss: 0.3634 - accuracy: 0.8754\n",
            "Epoch 14/20\n",
            "321/321 [==============================] - 316s 984ms/step - loss: 0.3319 - accuracy: 0.8821\n",
            "Epoch 15/20\n",
            "321/321 [==============================] - 316s 983ms/step - loss: 0.3087 - accuracy: 0.8903\n",
            "Epoch 16/20\n",
            "321/321 [==============================] - 316s 983ms/step - loss: 0.3011 - accuracy: 0.8910\n",
            "Epoch 17/20\n",
            "321/321 [==============================] - 316s 983ms/step - loss: 0.2857 - accuracy: 0.8987\n",
            "Epoch 18/20\n",
            "321/321 [==============================] - 316s 983ms/step - loss: 0.2719 - accuracy: 0.9041\n",
            "Epoch 19/20\n",
            "321/321 [==============================] - 314s 977ms/step - loss: 0.2523 - accuracy: 0.9064\n",
            "Epoch 20/20\n",
            "321/321 [==============================] - 314s 977ms/step - loss: 0.2368 - accuracy: 0.9133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AYrMYbm9b1xF"
      },
      "outputs": [],
      "source": [
        "def test_generate(TEST_DIR):\n",
        "  test_datagen = ImageDataGenerator(\n",
        "      rescale=1./255)\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  test_generator = test_datagen.flow_from_directory(directory=TEST_DIR,\n",
        "                                                      class_mode='categorical',\n",
        "                                                      batch_size = 1,\n",
        "                                                      target_size=(img_width, img_height),\n",
        "                                                      shuffle = False,\n",
        "                                                      classes=['.'])\n",
        "  return test_generator"
      ],
      "id": "AYrMYbm9b1xF"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9WmDcFjXcC1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3cf83bb-3b3e-43aa-f75f-6d9cb7b7887e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1618 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "test_generator = test_generate(test_dir)"
      ],
      "id": "9WmDcFjXcC1H"
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = {0 : 10, 1 : 11, 2 : 12, 3 : 13, 4 : 14, 5 : 15, 6 : 16, 7 : 17, 8 : 18, 9 : 19, 10 : 1, 11 : 20, 12 : 21, 13 : 22, 14 : 23, 15 : 24, 16 : 25, 17 : 26, 18 : 27, 19 : 28, 20 : 29, 21 : 2, 22 : 3, 23 : 4, 24 : 5, 25 : 6, 26 : 7, 27 : 8, 28 : 9}"
      ],
      "metadata": {
        "id": "wJokdSXM5iN9"
      },
      "execution_count": 20,
      "outputs": [],
      "id": "wJokdSXM5iN9"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NVSWKkCUd_ew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eaa775b-166f-43d3-dab4-2814292b0ce5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "predict_proba = m.predict_generator(test_generator)\n",
        "predict = np.argmax(predict_proba, axis = 1)\n",
        "predict = np.vectorize(dictionary.get)(predict)"
      ],
      "id": "NVSWKkCUd_ew"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NbpcEm4DnS0F"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame()\n",
        "\n",
        "filenames = list()\n",
        "for filename in test_generator.filenames:\n",
        "  if filename.endswith(\".jpg\"):\n",
        "    filenames.append(filename[2:])\n",
        "submission[\"id.jpg\"] = filenames\n",
        "\n",
        "submission[\"label\"] = predict\n",
        "\n",
        "submission.to_csv(\"/content/drive/MyDrive/submission_effnet_m_adam.csv\", index = False)"
      ],
      "id": "NbpcEm4DnS0F"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/drive/MyDrive/submission_effnet_m_adam.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gZuWnipiV0Zc",
        "outputId": "6f507a3b-2ac0-4077-90f6-c85fcef25b47"
      },
      "id": "gZuWnipiV0Zc",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_61ccbd17-e5c1-43f5-999a-2048a50cee1a\", \"submission_effnet_m_adam.csv\", 155458)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1DNgluq0V0K1"
      },
      "id": "1DNgluq0V0K1"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "FINAL_fine_EfficientNet_m_adam_refine_alldata.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
